{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3872516c-c8ff-4e45-b8f6-4b1dd95e5192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings  # Import the warnings module\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the experimental data\n",
    "data = {\n",
    "    'Firing_Temp': [750, 750, 850, 850, 950, 950, 1050, 1050],\n",
    "    'Clay_Type': ['ABC', 'XYZ', 'ABC', 'XYZ', 'ABC', 'XYZ', 'ABC', 'XYZ'],\n",
    "    'Comp_Strength': [7.85, 9.95, 8.15, 10.55, 9.78, 11.65, 10.25, 12.55],\n",
    "    'Weight_Loss': [1.75, 2.45, 2.05, 2.85, 1.95, 3.05, 2.15, 3.25],\n",
    "    'Bulk_Density': [1.48, 1.37, 1.52, 1.38, 1.56, 1.34, 1.60, 1.36],\n",
    "    'Porosity': [18.35, 25.50, 19.85, 24.10, 17.75, 26.20, 18.65, 23.50]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Encode categorical variable\n",
    "le = LabelEncoder()\n",
    "df['Clay_Type'] = le.fit_transform(df['Clay_Type'])\n",
    "\n",
    "# Define the feature columns and target columns\n",
    "features = ['Firing_Temp', 'Clay_Type']\n",
    "targets = ['Comp_Strength', 'Weight_Loss', 'Bulk_Density', 'Porosity']\n",
    "\n",
    "# Initialize the dictionary to store the results\n",
    "results = {\n",
    "    'Outcome': [],\n",
    "    'Number_of_Trees': [],\n",
    "    'Max_Depth': [],\n",
    "    'Firing_Temp_Importance': [],\n",
    "    'Clay_Type_Importance': [],\n",
    "    'Variation_Explained (%)': [],\n",
    "    'MSE_OOB': [],\n",
    "    'Pseudo_R2': []\n",
    "}\n",
    "\n",
    "# Hyperparameter grid for XGBoost\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 500, 1000],\n",
    "    'max_depth': [3, 6, 9, 12],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "all_predictions = {}\n",
    "\n",
    "for target in targets:\n",
    "    xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', random_state=99)\n",
    "    grid_search = GridSearchCV(estimator=xgb_reg, param_grid=param_grid, cv=kf, scoring='r2')\n",
    "    grid_search.fit(df[features], df[target])\n",
    "\n",
    "    best_xgb = grid_search.best_estimator_\n",
    "\n",
    "    # Get the feature importances\n",
    "    importances = best_xgb.feature_importances_\n",
    "    firing_temp_imp = importances[0]\n",
    "    clay_type_imp = importances[1]\n",
    "\n",
    "    # Calculate the metrics\n",
    "    predictions = best_xgb.predict(df[features])\n",
    "    all_predictions[target] = predictions\n",
    "\n",
    "    mse = mean_squared_error(df[target], predictions)\n",
    "    r2 = r2_score(df[target], predictions)\n",
    "    variation_explained = best_xgb.score(df[features], df[target]) * 100  # Convert to percentage\n",
    "    pseudo_r2 = r2\n",
    "\n",
    "    # Append the results to the dictionary\n",
    "    results['Outcome'].append(target)\n",
    "    results['Number_of_Trees'].append(grid_search.best_params_['n_estimators'])\n",
    "    results['Max_Depth'].append(grid_search.best_params_['max_depth'])\n",
    "    results['Firing_Temp_Importance'].append(firing_temp_imp)\n",
    "    results['Clay_Type_Importance'].append(clay_type_imp)\n",
    "    results['Variation_Explained (%)'].append(variation_explained)\n",
    "    results['MSE_OOB'].append(mse)\n",
    "    results['Pseudo_R2'].append(pseudo_r2)\n",
    "\n",
    "# Convert the results dictionary to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results in a nicely formatted table\n",
    "display(results_df)\n",
    "\n",
    "# Optionally, export the results to an Excel sheet\n",
    "results_df.to_excel('xgboost_results.xlsx', index=False)\n",
    "\n",
    "# Replicate the data 6 times (8 experiments * 6 = 48 data points)\n",
    "replication_factor = 6\n",
    "\n",
    "experimental_compressive_strength = np.tile(df['Comp_Strength'], replication_factor)\n",
    "predictive_compressive_strength = np.tile(all_predictions['Comp_Strength'], replication_factor)\n",
    "\n",
    "experimental_Weight_Loss = np.tile(df['Weight_Loss'], replication_factor)\n",
    "predictive_Weight_Loss = np.tile(all_predictions['Weight_Loss'], replication_factor)\n",
    "\n",
    "experimental_Bulk_Density = np.tile(df['Bulk_Density'], replication_factor)\n",
    "predictive_Bulk_Density = np.tile(all_predictions['Bulk_Density'], replication_factor)\n",
    "\n",
    "experimental_Porosity = np.tile(df['Porosity'], replication_factor)\n",
    "predictive_Porosity = np.tile(all_predictions['Porosity'], replication_factor)\n",
    "\n",
    "# Create the plots\n",
    "plt.figure(figsize=(10, 10))  # Increase the height for better spacing\n",
    "\n",
    "# Plot for Compressive Strength\n",
    "plt.subplot(4, 1, 1)\n",
    "plt.plot(experimental_compressive_strength, label='Experimental Compressive Strength', color='black')\n",
    "plt.plot(predictive_compressive_strength, label='Predictive Compressive Strength', color='blue')\n",
    "plt.xlabel('Experiment Number')\n",
    "plt.ylabel('Compressive Strength (MPa)')\n",
    "plt.legend()\n",
    "plt.title('Comparison of Experimental and Predictive Compressive Strength')\n",
    "\n",
    "# Plot for Weight Loss\n",
    "plt.subplot(4, 1, 2)\n",
    "plt.plot(experimental_Weight_Loss, label='Experimental Weight Loss', color='black')\n",
    "plt.plot(predictive_Weight_Loss, label='Predictive Weight Loss', color='blue')\n",
    "plt.xlabel('Experiment Number')\n",
    "plt.ylabel('Weight Loss')\n",
    "plt.legend()\n",
    "plt.title('Comparison of Experimental and Predictive Weight Loss')\n",
    "\n",
    "# Plot for Bulk Density\n",
    "plt.subplot(4, 1, 3)\n",
    "plt.plot(experimental_Bulk_Density, label='Experimental Bulk Density', color='black')\n",
    "plt.plot(predictive_Bulk_Density, label='Predictive Bulk Density', color='blue')\n",
    "plt.xlabel('Experiment Number')\n",
    "plt.ylabel('Bulk Density (g/cmÂ³)')  # Correct unit for Bulk Density\n",
    "plt.legend()\n",
    "plt.title('Comparison of Experimental and Predictive Bulk Density')\n",
    "\n",
    "# Plot for Porosity\n",
    "plt.subplot(4, 1, 4)\n",
    "plt.plot(experimental_Porosity, label='Experimental Porosity', color='black')\n",
    "plt.plot(predictive_Porosity, label='Predictive Porosity', color='blue')\n",
    "plt.xlabel('Experiment Number')\n",
    "plt.ylabel('Porosity')\n",
    "plt.legend()\n",
    "plt.title('Comparison of Experimental and Predictive Porosity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparison_plots_kfold.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5e6b3d-eafa-4282-83b4-dc5fa3977d84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
